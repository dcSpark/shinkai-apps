import * as fs from 'fs';
import * as path from 'path';
import * as process from 'process';
import fetch from 'node-fetch';

function formatBytesAsHexLines(data: Buffer, indent: string = "    ", lineLength: number = 16): string {
  const bytesArray: string[] = [];
  for (let i = 0; i < data.length; i++) {
    bytesArray.push(`0x${data[i].toString(16).padStart(2, '0').toUpperCase()}`);
  }
  const lines: string[] = [];
  for (let i = 0; i < bytesArray.length; i += lineLength) {
    const line = bytesArray.slice(i, i + lineLength).join(', ');
    lines.push(indent + line);
  }
  return lines.join(",\n");
}

function generatePartFile(partData: Buffer, partNumber: number): void {
  const formattedBytes = formatBytesAsHexLines(partData);
  const fileContent = `// This file was automatically generated from a part of the GGUF model.
// Do not edit manually.
#[allow(clippy::all)]
pub const MODEL_DATA_PART${partNumber}: &[u8] = &[
${formattedBytes}
];
`;
  const fileName = path.join(`./apps/shinkai-desktop/src-tauri/src/models/embedding_model_part${partNumber}.rs`);
  
  // Create directory if it doesn't exist
  const dirName = path.dirname(fileName);
  fs.mkdirSync(dirName, { recursive: true });
  
  fs.writeFileSync(fileName, fileContent, 'utf8');
  console.log(`Generated ${fileName}`);
}

function generateModelFiles(numParts: number) {
  // Generate imports file
  let modelFile = '// embedding_model.rs\n';
  modelFile += '// This file joins the GGUF model parts generated by the conversion script.\n';
  modelFile += '// Do not edit manually.\n\n';

  // Add imports
  for (let i = 1; i <= numParts; i++) {
    modelFile += `#[path = "embedding_model_part${i}.rs"]\n`;
    modelFile += `pub(crate) mod embedding_model_part${i};\n\n`;
  }

  // Add get_model_data function
  modelFile += 'pub fn get_model_data() -> &\'static [u8] {\n';
  modelFile += '    use std::sync::OnceLock;\n';
  modelFile += '    static FULL_MODEL_DATA: OnceLock<Vec<u8>> = OnceLock::new();\n\n';
  modelFile += '    FULL_MODEL_DATA.get_or_init(|| {\n';
  
  // Add capacity calculation
  modelFile += '        let mut result = Vec::with_capacity(\n            ';
  modelFile += Array.from({length: numParts}, (_, i) =>
    `embedding_model_part${i + 1}::MODEL_DATA_PART${i + 1}.len()`
  ).join(' +\n            ');
  modelFile += '\n        );\n\n';

  // Add extend_from_slice calls
  for (let i = 1; i <= numParts; i++) {
    modelFile += `        result.extend_from_slice(embedding_model_part${i}::MODEL_DATA_PART${i});\n`;
  }

  modelFile += '\n        result\n';
  modelFile += '    }).as_slice()\n';
  modelFile += '}\n\n';
  
  modelFile += 'pub const MODEL_NAME: &str = "snowflake-arctic-embed:xs";\n\n';
  modelFile += 'pub fn get_model_name() -> &\'static str {\n';
  modelFile += '    MODEL_NAME\n';
  modelFile += '}\n';

  fs.writeFileSync('./apps/shinkai-desktop/src-tauri/src/models/embedding_model.rs', modelFile);
}

async function convertGGUFSplit(ggufUrl: string) {
  // Download the binary data from the URL
  const response = await fetch(ggufUrl);
  if (!response.ok) {
    throw new Error(`Failed to download file: ${response.statusText}`);
  }
  const data = Buffer.from(await response.arrayBuffer());
  const totalLength = data.length;
  
  // Reduce the chunk size to ~1MB to avoid constant evaluation issues
  const partSize = 1024 * 4096; // 4MB chunks
  const numParts = Math.ceil(totalLength / partSize);

  for (let i = 0; i < numParts; i++) {
    const start = i * partSize;
    const end = Math.min(start + partSize, totalLength);
    const partData = data.slice(start, end);
    generatePartFile(partData, i + 1);
  }
  
  // After generating all parts, generate the model files
  generateModelFiles(numParts);
  console.log(`Generated ${numParts} embedding parts and support files successfully.`);
}


const ggufUrl = process.argv[2] ?? 'https://huggingface.co/ChristianAzinn/snowflake-arctic-embed-xs-gguf/resolve/main/snowflake-arctic-embed-xs-f16.GGUF?download=true';

// Convert the main function call to handle the async operation
convertGGUFSplit(ggufUrl).catch(error => {
  console.error('Error:', error);
  process.exit(1);
});
